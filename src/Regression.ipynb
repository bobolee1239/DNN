{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning HW1\n",
    "---\n",
    "#### Problem1\n",
    "- ID: A061508\n",
    "- NAME: 李宗翰\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DNN_Jupyter import *\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILENAME = '../Dataset/energy_efficiency_data.csv'\n",
    "NUM_TRAIN = 576"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFile(filename):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "    ------------------------------\n",
    "    1. rawDatas: <list of numpy.ndarray> shape = (#samples, #features).\n",
    "    2. targets: <numpy.ndarray> shape = (#samples, ) corresponds to datas.\n",
    "    3. datas: <list of numpy.ndarray> normalize rawDatas with infinity norm.\n",
    "    \n",
    "    \"\"\"\n",
    "    df = pd.read_csv(filename)\n",
    "\n",
    "    indexOfOrientation = 5\n",
    "    indexOfGlazingAreaDistribution = 7\n",
    "    indexOfTarget = 8\n",
    "    \n",
    "    rawDatas = [] # list to store features\n",
    "    maxValues = [0.0] * 6 # dictionary<Int, Float> establish table to check out infinite norm\n",
    "    targets = []\n",
    "    \n",
    "    for rawData in df.values:\n",
    "        sample = []\n",
    "        \n",
    "        ## Dealing with Normal Vector\n",
    "        for idx in (0, 1, 2, 3, 4, 6):\n",
    "            sample.append(rawData[idx])\n",
    "            for idx, var in enumerate(sample):\n",
    "                if var > maxValues[idx]: maxValues[idx] = var\n",
    "                   \n",
    "        ## Dealing with One Hot Vector\n",
    "        #  1. Orientation\n",
    "        indexOfOne = (rawData[indexOfOrientation] - 1) % 4\n",
    "        for i in range(4):\n",
    "            if i == indexOfOne: sample.append(1)\n",
    "            else: sample.append(0)\n",
    "                \n",
    "        #  2.Glazing Area Distribution\n",
    "        indexOfOne = (rawData[indexOfGlazingAreaDistribution] % 6) - 1\n",
    "        for i in range(5):\n",
    "            if i == indexOfOne: sample.append(1)\n",
    "            else: sample.append(0)\n",
    "        \n",
    "        rawDatas.append(np.array(sample))\n",
    "        \n",
    "        targets.append(rawData[indexOfTarget])\n",
    "     \n",
    "    normalizedDatas = []\n",
    "    ## Normalize Data\n",
    "    for sample in rawDatas:\n",
    "        tmp = [0.0] * 15\n",
    "        for idx in range(len(maxValues)):\n",
    "            tmp[idx] = sample[idx] / maxValues[idx]\n",
    "        for idx in range(6, 15):\n",
    "            tmp[idx] = sample[idx]\n",
    "        normalizedDatas.append(np.array(tmp))\n",
    "    \n",
    "    return (rawDatas, normalizedDatas, np.array(targets))\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ =='__main__':\n",
    "    rawDatas, normalizedDatas, targets = readFile(FILENAME)\n",
    "    dataSet = list(zip(normalizedDatas, targets))\n",
    "    \n",
    "    np.random.shuffle(dataSet)\n",
    "    trainingSet = dataSet[:NUM_TRAIN]\n",
    "    testingSet = dataSet[NUM_TRAIN:]\n",
    "    \n",
    "    dnn = DNN(learningRate = 0.001, costFunction = 'LMS')\n",
    "    dnn.add(numberOfInput = 15, numberOfNodes = 10, activeFunc = ReLu())\n",
    "    dnn.add(numberOfNodes = 10, activeFunc = ReLu())\n",
    "    dnn.add(numberOfNodes = 1, activeFunc = ActiveFunctions())\n",
    "\n",
    "    dnn.fit(trainingSet, toPlot=True, toPrint=False)#, maxEpochs=1000)\n",
    "    dnn.predict(trainingSet, toPlot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn.predict(testingSet, toPlot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Testing\n",
    "\n",
    "# df = pd.read_csv(FILENAME)\n",
    "# for value in df.values:\n",
    "#     print(value)\n",
    "    \n",
    "    \n",
    "# #     print('RAW\\n---------------------------------------')\n",
    "# #     for d in rawDatas:\n",
    "# #         print(d)\n",
    "        \n",
    "# #     print('NORMALIZE\\n---------------------------------')\n",
    "# #     for d in normalizedDatas:\n",
    "# #         print(d)\n",
    "    \n",
    "#     print('TARGET\\n-------------------------------------')\n",
    "#     for t in targets:\n",
    "#         print(t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
